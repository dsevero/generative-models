{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsevero/generative-models/blob/master/experiments/GAN/notebooks/goodfellow_2014.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69jryAXYtlmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVCHBrRRuUUY",
        "colab_type": "text"
      },
      "source": [
        "# Generative Adversarial Nets (Goodfellow 2014)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfJmN-YMroqt",
        "colab_type": "text"
      },
      "source": [
        "**References:**\n",
        "* https://arxiv.org/pdf/1406.2661.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0j0DEAPANpt",
        "colab_type": "text"
      },
      "source": [
        "## Autograd\n",
        "(doesn't work very well :/, training time is harsh maybe using jax will suffice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8SOx2KGriTc",
        "colab_type": "text"
      },
      "source": [
        "**References:** \n",
        "* https://github.com/HIPS/autograd/blob/master/examples/generative_adversarial_net.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyDcYCjnhb0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1pQTYwsDlAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPDM2dRnt5gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# necessary for autograd compatibility\n",
        "!pip install scipy==1.1.0 -q\n",
        "\n",
        "# update tensorflow\n",
        "!pip install tensorflow==2.0.0b1 -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5INWa4setf75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import autograd.numpy as np\n",
        "import autograd.numpy.random as npr\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from autograd import grad\n",
        "from autograd.misc import flatten\n",
        "from autograd.misc.optimizers import adam, rmsprop, sgd\n",
        "from scipy.stats import norm\n",
        "\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSdGVpxdD-Aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_image(image):\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p756YZQnvFZp",
        "colab_type": "text"
      },
      "source": [
        "### Definitions and Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIimoT6YsJER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x):       \n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def sigmoid(x):    \n",
        "    return 0.5 * (np.tanh(x) + 1.0)\n",
        "\n",
        "def logsigmoid(x): \n",
        "    return x - np.logaddexp(0, x)\n",
        "\n",
        "def init_random_params(scale, layer_sizes, rs=npr.RandomState(0)):\n",
        "    \"\"\"Build a list of (weights, biases) tuples,\n",
        "       one for each layer in the net.\"\"\"\n",
        "    return [(scale * rs.randn(m, n),   # weight matrix\n",
        "             scale * rs.randn(n))      # bias vector\n",
        "            for m, n in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
        "\n",
        "def batch_normalize(activations):\n",
        "    mbmean = np.mean(activations, axis=0, keepdims=True)\n",
        "    return (activations - mbmean) / (np.std(activations, axis=0, keepdims=True) + 1)\n",
        "\n",
        "def neural_net_predict(params, inputs, use_batch_norm=True):\n",
        "    \"\"\"Params is a list of (weights, bias) tuples.\n",
        "       inputs is an (N x D) matrix.\"\"\"\n",
        "    inpW, inpb = params[0]\n",
        "    inputs = relu(np.dot(inputs, inpW) + inpb)\n",
        "    for W, b in params[1:-1]:\n",
        "        outputs = np.dot(inputs, W) + b\n",
        "        if use_batch_norm:\n",
        "            outputs = batch_normalize(outputs)\n",
        "        inputs = relu(outputs)\n",
        "    outW, outb = params[-1]\n",
        "    outputs = np.dot(inputs, outW) + outb\n",
        "    return outputs\n",
        "\n",
        "def generator(params, noise):\n",
        "    samples = neural_net_predict(params, noise)\n",
        "    return sigmoid(samples)\n",
        "\n",
        "def discriminator(params, inputs):\n",
        "    samples = neural_net_predict(params, inputs)\n",
        "    return sigmoid(samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DA1eNmWvM4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = 5*((np.eye(3), np.zeros(3)),)\n",
        "x =  npr.randn(9).reshape((3,3))\n",
        "zeros = np.array([0, 0, 0])\n",
        "\n",
        "assert (batch_normalize(zeros) == zeros).all()\n",
        "assert (batch_normalize(np.array([-1, 1])) == np.array([-0.5, 0.5])).all()\n",
        "assert (batch_normalize(np.array([[-1, 1], [-2, 2]])) == np.array([[1/3, -1/3], [-1/3, 1/3]])).all()\n",
        "\n",
        "assert (neural_net_predict(params, x, False) == relu(x)).all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7buAOgGK6FuJ",
        "colab_type": "text"
      },
      "source": [
        "### 5 Experiments (MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLYwGW7U6YqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "param_scale = 0.001\n",
        "batch_size = 1_000 # must divide 70_000.\n",
        "num_epochs = 10\n",
        "num_batches = int(70_000/batch_size)\n",
        "\n",
        "\n",
        "# Load, concatenate and reshape the data.\n",
        "# Here we don't distinguish between train and test.\n",
        "# Final dimensions are (batch, image_example, image_row, image_column)\n",
        "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()\n",
        "images = (np.concatenate((train_images, test_images))\n",
        "            .reshape((num_batches, batch_size, 28, 28))) / 255\n",
        "\n",
        "# Model hyper-parameters\n",
        "noise_dim = 100\n",
        "gen_layer_sizes = [noise_dim, 50, 50, 784]\n",
        "dsc_layer_sizes = [gen_layer_sizes[-1], 50, 50, 1]\n",
        "\n",
        "# Initialize NN params. for G and D\n",
        "init_gen_params = init_random_params(param_scale, gen_layer_sizes)\n",
        "init_dsc_params = init_random_params(param_scale, dsc_layer_sizes)\n",
        "\n",
        "print('images.shape:', images.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h15wslYoDSjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Real image\n",
        "show_image(images[0, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTx70Qo9Gwil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initial random image from G\n",
        "z = npr.rand(1, noise_dim)\n",
        "fake_image = generator(init_gen_params, z)\n",
        "show_image(fake_image.reshape(28, 28))\n",
        "\n",
        "# What D knows about the random image (i.e. nothing!)\n",
        "discriminator(init_dsc_params, fake_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R4Kj-_ZNcri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Even real images he has no clue on what is going on!\n",
        "five_real_images = images[0, :5]\n",
        "discriminator(init_dsc_params, five_real_images.reshape(5, 28*28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJQ2aop0Ol2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train\n",
        "n_dsc_steps = 1\n",
        "params_dsc = init_dsc_params\n",
        "opt = rmsprop\n",
        "\n",
        "def objective_outer(params_gen, t):\n",
        "    global params_dsc\n",
        "    real_data = images[t % num_batches].reshape(batch_size, 28*28)\n",
        "    \n",
        "    def objective_inner(params_dsc, t):\n",
        "        noise_inner = npr.rand(batch_size, noise_dim)\n",
        "        fake_data_inner = generator(params_gen, noise_inner)\n",
        "        return(np.log(discriminator(params_dsc, real_data)).mean() + \n",
        "               np.log(1 - discriminator(params_dsc, fake_data_inner))).mean()\n",
        "        \n",
        "    params_dsc = opt(grad(objective_inner), params_dsc,\n",
        "                     step_size=0.01, num_iters=n_dsc_steps)\n",
        "    \n",
        "    noise_outer = npr.rand(batch_size, noise_dim)\n",
        "    fake_data_outer = generator(params_gen, noise_outer)\n",
        "    return np.log(discriminator(params_dsc, fake_data_outer)).mean()\n",
        "\n",
        "z = npr.rand(1, noise_dim)\n",
        "def callback(params_gen, t, gradient):    \n",
        "    print(f'Iteration {t};')\n",
        "#     print(f'z.mean() = {z.mean()}')\n",
        "#     print(f'params_gen = {params_gen[0][0].mean()}')\n",
        "#     print(f'params_dsc = {params_dsc[0][0].mean()}')\n",
        "    \n",
        "    fake_image = generator(params_gen, z)\n",
        "    show_image(fake_image.reshape(28, 28))\n",
        "\n",
        "params_gen = opt(grad(objective_outer), \n",
        "                 init_gen_params,\n",
        "                 step_size=0.1,\n",
        "                 num_iters=num_epochs*num_batches,\n",
        "                 callback=callback)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXrojyobAUOt",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLQ7CstOrPVh",
        "colab_type": "text"
      },
      "source": [
        "**References:**\n",
        "* https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK4a5WkfAWQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"GPU Available? =\", torch.cuda.is_available())\n",
        "print(\"Modules versions:\")\n",
        "!pip freeze | grep -E '^numpy==|^pandas==|^torch==|^torchvision=='"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eol7ToP7sAUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Linear(in_feat, out_feat)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(latent_dim, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), *img_shape)\n",
        "        return img\n",
        "\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(img_shape)), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQnUX8Cns8Kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_shape = (1, 28, 28)\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "latent_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}