{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsevero/generative-models/blob/master/experiments/GAN/notebooks/goodfellow_2014.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVCHBrRRuUUY",
        "colab_type": "text"
      },
      "source": [
        "# Generative Adversarial Nets (Goodfellow 2014)\n",
        "https://arxiv.org/pdf/1406.2661.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPDM2dRnt5gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# necessary for autograd compatibility\n",
        "!pip install scipy==1.1.0 -q\n",
        "\n",
        "# update tensorflow\n",
        "!pip install tensorflow==2.0.0b1 -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5INWa4setf75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import autograd.numpy as np\n",
        "import autograd.numpy.random as npr\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from autograd import grad\n",
        "from autograd.misc import flatten\n",
        "    \n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "Ï€ = np.pi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p756YZQnvFZp",
        "colab_type": "text"
      },
      "source": [
        "## Definitions and Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIimoT6YsJER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reference: \n",
        "# https://github.com/HIPS/autograd/blob/master/examples/generative_adversarial_net.py\n",
        "\n",
        "def relu(x):       \n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def sigmoid(x):    \n",
        "    return 0.5 * (np.tanh(x) + 1.0)\n",
        "\n",
        "def logsigmoid(x): \n",
        "    return x - np.logaddexp(0, x)\n",
        "\n",
        "def init_random_params(scale, layer_sizes, rs=npr.RandomState(0)):\n",
        "    \"\"\"Build a list of (weights, biases) tuples,\n",
        "       one for each layer in the net.\"\"\"\n",
        "    return [(scale * rs.randn(m, n),   # weight matrix\n",
        "             scale * rs.randn(n))      # bias vector\n",
        "            for m, n in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
        "\n",
        "def batch_normalize(activations):\n",
        "    mbmean = np.mean(activations, axis=0, keepdims=True)\n",
        "    return (activations - mbmean) / (np.std(activations, axis=0, keepdims=True) + 1)\n",
        "\n",
        "def neural_net_predict(params, inputs, use_batch_norm=True):\n",
        "    \"\"\"Params is a list of (weights, bias) tuples.\n",
        "       inputs is an (N x D) matrix.\"\"\"\n",
        "    inpW, inpb = params[0]\n",
        "    inputs = relu(np.dot(inputs, inpW) + inpb)\n",
        "    for W, b in params[1:-1]:\n",
        "        outputs = np.dot(inputs, W) + b\n",
        "        if use_batch_norm:\n",
        "            outputs = batch_normalize(outputs)\n",
        "        inputs = relu(outputs)\n",
        "    outW, outb = params[-1]\n",
        "    outputs = np.dot(inputs, outW) + outb\n",
        "    return outputs\n",
        "\n",
        "def generate_from_noise(gen_params, num_samples, noise_dim, rs):\n",
        "    noise = rs.rand(num_samples, noise_dim)\n",
        "    samples = neural_net_predict(gen_params, noise)\n",
        "    return sigmoid(samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DA1eNmWvM4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = 2*((np.eye(3), np.zeros(3)),)\n",
        "\n",
        "assert (batch_normalize([0, 0, 0]) == [0, 0, 0]).all()\n",
        "assert (batch_normalize([-1, 1]) == [-0.5, 0.5]).all()\n",
        "assert (batch_normalize([[-1, 1], [-2, 2]]) == [[1/3, -1/3], [-1/3, 1/3]]).all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNGEqZ2q0rBS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4cf1888b-85c1-4ef2-bf76-6f48e8942c15"
      },
      "source": [
        "x = np.ones((3,3)).dot()\n",
        "neural_net_predict(params, x, False)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fN9AQnS1XzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "87346206-d5d0-4904-8275-e9baf63b1571"
      },
      "source": [
        "np.ones((3,3))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    }
  ]
}